{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa41504c-69ae-4f7c-96b9-ee9dd9ad61f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'robustbench'...\n",
      "remote: Enumerating objects: 4825, done.\u001b[K\n",
      "remote: Counting objects: 100% (375/375), done.\u001b[K\n",
      "remote: Compressing objects: 100% (200/200), done.\u001b[K\n",
      "remote: Total 4825 (delta 242), reused 210 (delta 175), pack-reused 4450 (from 3)\u001b[K\n",
      "Receiving objects: 100% (4825/4825), 6.11 MiB | 7.37 MiB/s, done.\n",
      "Resolving deltas: 100% (3137/3137), done.\n",
      "/workspace/robustbench\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /workspace/robustbench\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting autoattack@ git+https://github.com/fra31/auto-attack.git@a39220048b3c9f2cca9a4d3a54604793c68eca7e#egg=autoattack (from robustbench==1.1)\n",
      "  Cloning https://github.com/fra31/auto-attack.git (to revision a39220048b3c9f2cca9a4d3a54604793c68eca7e) to /tmp/pip-install-y8jiu9ly/autoattack_c08229ea117f4c6aa02a8b24ef60d177\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/fra31/auto-attack.git /tmp/pip-install-y8jiu9ly/autoattack_c08229ea117f4c6aa02a8b24ef60d177\n",
      "  Running command git rev-parse -q --verify 'sha^a39220048b3c9f2cca9a4d3a54604793c68eca7e'\n",
      "  Running command git fetch -q https://github.com/fra31/auto-attack.git a39220048b3c9f2cca9a4d3a54604793c68eca7e\n",
      "  Resolved https://github.com/fra31/auto-attack.git to commit a39220048b3c9f2cca9a4d3a54604793c68eca7e\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from robustbench==1.1) (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from robustbench==1.1) (0.16.0+cu118)\n",
      "Collecting torchdiffeq (from robustbench==1.1)\n",
      "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
      "Collecting geotorch (from robustbench==1.1)\n",
      "  Downloading geotorch-0.3.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from robustbench==1.1) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.10/dist-packages (from robustbench==1.1) (1.24.1)\n",
      "Requirement already satisfied: Jinja2~=3.1.2 in /usr/local/lib/python3.10/dist-packages (from robustbench==1.1) (3.1.2)\n",
      "Collecting tqdm>=4.56.1 (from robustbench==1.1)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas>=1.3.5 (from robustbench==1.1)\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting timm==1.0.9 (from robustbench==1.1)\n",
      "  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gdown==5.1.0 (from robustbench==1.1)\n",
      "  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from robustbench==1.1) (6.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==5.1.0->robustbench==1.1) (4.12.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==5.1.0->robustbench==1.1) (3.9.0)\n",
      "Collecting huggingface_hub (from timm==1.0.9->robustbench==1.1)\n",
      "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from timm==1.0.9->robustbench==1.1)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2~=3.1.2->robustbench==1.1) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->robustbench==1.1) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.3.5->robustbench==1.1)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.3.5->robustbench==1.1)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->robustbench==1.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->robustbench==1.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->robustbench==1.1) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->robustbench==1.1) (2022.12.7)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->robustbench==1.1) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->robustbench==1.1) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->robustbench==1.1) (3.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->robustbench==1.1) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->robustbench==1.1) (2.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.8.2->robustbench==1.1) (9.3.0)\n",
      "Collecting scipy>=1.4.0 (from torchdiffeq->robustbench==1.1)\n",
      "  Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->robustbench==1.1) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==5.1.0->robustbench==1.1) (2.5)\n",
      "Collecting fsspec (from torch>=1.7.1->robustbench==1.1)\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm==1.0.9->robustbench==1.1) (23.2)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown==5.1.0->robustbench==1.1)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->robustbench==1.1) (1.3.0)\n",
      "Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
      "Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading geotorch-0.3.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.9/507.9 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.0/468.0 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Building wheels for collected packages: robustbench, autoattack\n",
      "  Building wheel for robustbench (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for robustbench: filename=robustbench-1.1-py3-none-any.whl size=194453 sha256=e2f94e096e87a42cf90efeba3269c434d03db489b57fad1ac203f888da968ca0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-bk3gg4wb/wheels/8b/ca/a6/2abb60e259ee4d8b5696d572f395f49c8aa7078a29cfa7b439\n",
      "  Building wheel for autoattack (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for autoattack: filename=autoattack-0.1-py3-none-any.whl size=36229 sha256=46612a066f3662e34f85265d586ceace3bc87f8ba80b1e234296ed1966329244\n",
      "  Stored in directory: /root/.cache/pip/wheels/72/59/98/10a8eb862dabff57be1d1e3b1a3664acc78da7667d2c835584\n",
      "Successfully built robustbench autoattack\n",
      "Installing collected packages: pytz, autoattack, tzdata, tqdm, scipy, safetensors, PySocks, fsspec, pandas, huggingface_hub, torchdiffeq, geotorch, gdown, timm, robustbench\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed PySocks-1.7.1 autoattack-0.1 fsspec-2025.2.0 gdown-5.1.0 geotorch-0.3.0 huggingface_hub-0.29.1 pandas-2.2.3 pytz-2025.1 robustbench-1.1 safetensors-0.5.2 scipy-1.15.2 timm-1.0.9 torchdiffeq-0.2.5 tqdm-4.67.1 tzdata-2025.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/RobustBench/robustbench\n",
    "%cd /workspace/robustbench/\n",
    "!pip3 install . --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f1aa331-1476-4339-ad2f-2f1081a30b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: robustbench 1.1\n",
      "Uninstalling robustbench-1.1:\n",
      "  Successfully uninstalled robustbench-1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip3 uninstall robustbench -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e33d65-e4ab-4d2e-bc46-a0d4263399f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/robustbench\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/robustbench/\n",
    "from robustbench import load_model\n",
    "import torch\n",
    "# Load a model from the model zoo\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = load_model(model_name='Peng2023Robust',\n",
    "                   dataset='cifar10',\n",
    "                   threat_model='Linf').to(device)\n",
    "net = load_model(model_name='Peng2023Robust',\n",
    "                   dataset='cifar10',\n",
    "                   threat_model='Linf').to(device)\n",
    "# Evaluate the Linf robustness of the model using AutoAttack\n",
    "#from robustbench.eval import benchmark\n",
    "#clean_acc, robust_acc = benchmark(model,\n",
    "#                                  dataset='cifar10',\n",
    "#                                  threat_model='Linf', device=device, eps=8/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41492212-3cc1-4298-a300-e1630d219aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchattacks in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
      "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (0.16.0+cu118)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (1.15.2)\n",
      "Requirement already satisfied: tqdm>=4.56.1 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (4.67.1)\n",
      "Requirement already satisfied: requests~=2.25.1 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.10/dist-packages (from torchattacks) (1.24.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks) (2022.12.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (2025.2.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->torchattacks) (2.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.8.2->torchattacks) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.1->torchattacks) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->torchattacks) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torchattacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae17c77c-a494-4935-a3ca-21112aa31578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "def set_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    import numpy as np\n",
    "    np.random.seed(seed)\n",
    "    torch.mps.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "transforms_train = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.RandomHorizontalFlip()])\n",
    "transforms_test = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"/cifar10/\",\n",
    "                               train=True,\n",
    "                               transform=transforms_test,\n",
    "                               download=True)\n",
    "testset = torchvision.datasets.CIFAR10(root=\"/cifar10/\",\n",
    "                               train=False,\n",
    "                               transform=transforms_test,\n",
    "                               download=True)\n",
    "set_seeds(0)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=1)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd51c5b4-c251-4aeb-8bba-5ed830acbd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "import math\n",
    "def evaluate_attacked_model(loader, phase, atk, limit=5000, model=model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    counter = 0\n",
    "    total_loss = 0.0\n",
    "    for data in loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        #print(labels)\n",
    "        model.train()\n",
    "        images = atk(images, labels)\n",
    "        model.eval()\n",
    "        outputs = model(images.to(device))\n",
    "        #print(outputs.shape)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        #print(outputs.data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if total >= limit:\n",
    "            break\n",
    "    print(f'{phase} accuracy: {100 * correct / total} ({correct} / {total}) %')\n",
    "    return correct, total_loss / math.ceil(limit / 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdd2aca9-abfb-4fca-9ae5-1f95ee55bf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 74.31640625 (761 / 1024) %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(761, 0.44063784016503227)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchattacks\n",
    "atk = torchattacks.PGD(model, steps=20)\n",
    "# 20-step PGD: 761 / 1024\n",
    "evaluate_attacked_model(testloader, \"test\", atk, limit=1000, model=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e320955c-07c3-45f6-88d0-b175f99d3bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ef9238e-fbd8-403f-9aac-5d626bd42f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001]\n",
      "[0,    25] loss: 0.44610306739807126\n",
      "[0,    50] loss: 0.4000282430648804\n",
      "[0,    75] loss: 0.370904735326767\n",
      "[0,   100] loss: 0.3372477114200592\n",
      "[0,   125] loss: 0.3378241276741028\n",
      "[0,   150] loss: 0.3339101159572601\n",
      "[0,   175] loss: 0.3083159124851227\n",
      "[0,   200] loss: 0.2938941514492035\n",
      "[0,   225] loss: 0.2775013089179993\n",
      "[0,   250] loss: 0.2770329761505127\n",
      "[0,   275] loss: 0.26669916629791257\n",
      "[0,   300] loss: 0.2691108500957489\n",
      "[0,   325] loss: 0.25969280779361725\n",
      "[0,   350] loss: 0.26386243760585787\n",
      "[0,   375] loss: 0.25311654806137085\n",
      "[0,   400] loss: 0.25883460104465483\n",
      "[0,   425] loss: 0.23149783432483673\n",
      "[0,   450] loss: 0.20211881995201111\n",
      "[0,   475] loss: 0.23929192304611205\n",
      "[0,   500] loss: 0.21034965813159942\n",
      "[0,   525] loss: 0.2344609558582306\n",
      "[0,   550] loss: 0.24165017634630204\n",
      "[0,   575] loss: 0.2013562110066414\n",
      "[0,   600] loss: 0.20244475394487382\n",
      "[0,   625] loss: 0.21512236326932907\n",
      "[0,   650] loss: 0.18775148451328277\n",
      "[0,   675] loss: 0.21841496855020523\n",
      "[0,   700] loss: 0.22049506783485412\n",
      "[0,   725] loss: 0.19132785856723786\n",
      "[0,   750] loss: 0.18847938895225524\n",
      "[0,   775] loss: 0.188740511238575\n",
      "[0,   800] loss: 0.19348350524902344\n",
      "[0,   825] loss: 0.18621280163526535\n",
      "[0,   850] loss: 0.20608254432678222\n",
      "[0,   875] loss: 0.20482206642627715\n",
      "[0,   900] loss: 0.18556081593036652\n",
      "[0,   925] loss: 0.16647021234035492\n",
      "[0,   950] loss: 0.16255728751420975\n",
      "[0,   975] loss: 0.19502876371145247\n",
      "[0,  1000] loss: 0.1671733781695366\n",
      "[0,  1025] loss: 0.17051306873559952\n",
      "[0,  1050] loss: 0.16524781316518783\n",
      "[0,  1075] loss: 0.1852294063568115\n",
      "[0,  1100] loss: 0.2084147137403488\n",
      "[0,  1125] loss: 0.2095381012558937\n",
      "[0,  1150] loss: 0.17513039231300354\n",
      "[0,  1175] loss: 0.1761925372481346\n",
      "[0,  1200] loss: 0.17131210386753082\n",
      "[0,  1225] loss: 0.1518893802165985\n",
      "[0,  1250] loss: 0.19124719649553298\n",
      "[0,  1275] loss: 0.19841058433055878\n",
      "[0,  1300] loss: 0.18725554317235946\n",
      "[0,  1325] loss: 0.15500491052865983\n",
      "[0,  1350] loss: 0.2082965737581253\n",
      "[0,  1375] loss: 0.17043882966041565\n",
      "[0,  1400] loss: 0.1614996987581253\n",
      "[0,  1425] loss: 0.19478295877575874\n",
      "[0,  1450] loss: 0.15383113592863082\n",
      "[0,  1475] loss: 0.1711700327694416\n",
      "[0,  1500] loss: 0.17439138218760492\n",
      "[0,  1525] loss: 0.16095372021198273\n",
      "[0,  1550] loss: 0.18528124928474426\n",
      "[0.0001]\n",
      "[1,    25] loss: 0.12208979219198227\n",
      "[1,    50] loss: 0.09615981489419938\n",
      "[1,    75] loss: 0.09241504117846489\n",
      "[1,   100] loss: 0.08832559794187546\n",
      "[1,   125] loss: 0.10043935120105743\n",
      "[1,   150] loss: 0.11792283341288566\n",
      "[1,   175] loss: 0.08632546693086623\n",
      "[1,   200] loss: 0.1146523992717266\n",
      "[1,   225] loss: 0.10246429488062858\n",
      "[1,   250] loss: 0.148412906229496\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m adv \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adv \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 50\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mpgd5\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m outputs \u001b[38;5;241m=\u001b[39m net(inputs) \u001b[38;5;66;03m# can we actually get rid of the clean samples completely?\u001b[39;00m\n\u001b[1;32m     52\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchattacks/attack.py:511\u001b[0m, in \u001b[0;36mAttack.__call__\u001b[0;34m(self, inputs, labels, *args, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_normalization_applied(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m     adv_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# adv_inputs = self.to_type(adv_inputs, self.return_type)\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recover_model_mode(given_training)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchattacks/attacks/pgd.py:63\u001b[0m, in \u001b[0;36mPGD.forward\u001b[0;34m(self, images, labels)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m     62\u001b[0m     adv_images\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43madv_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargeted:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchattacks/attack.py:79\u001b[0m, in \u001b[0;36mAttack.get_logits\u001b[0;34m(self, inputs, labels, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalization_applied \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize(inputs)\n\u001b[0;32m---> 79\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/robustbench/robustbench/model_zoo/architectures/robustarch_wide_resnet.py:261\u001b[0m, in \u001b[0;36mNormalizedWideResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    258\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(x, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mis_cuda:\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m#if self.mean_cuda is None\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_cuda \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# TODO: improve this.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd_cuda \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    263\u001b[0m     out \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_cuda) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd_cuda\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchattacks\n",
    "LR = 0.0001\n",
    "import torch.optim as optim\n",
    "import random\n",
    "MODELTYPE = \"Peng2023Robust_extratrain\"\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 1)\n",
    "pgd5 = torchattacks.PGD(net, steps=5)\n",
    "pgd40 = torchattacks.PGD(net, steps=40)\n",
    "aa = torchattacks.AutoAttack(net)\n",
    "#pgd10.set_mode_targeted_least_likely(1)\n",
    "vanila = torchattacks.VANILA(net)\n",
    "record, record_fn = float(\"inf\"), \"\"\n",
    "for epoch in range(4):  # loop over the dataset multiple times\n",
    "    # test the 625 / 125 spacing\n",
    "    # to even out the intervals when plotted out as a graph\n",
    "    print(scheduler.get_last_lr())\n",
    "    running_loss = 0.0\n",
    "    adv_loss, clean_loss, adv_runs = 0.0, 0.0, 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        if i % 125 == 0:\n",
    "            # sample 2000 data points from the train and test sets\n",
    "            # try: borrow the batch mixing method from curriculum adversarial training and merge two batches into one big batch\n",
    "            # will need to adjust the batch size to 8 though\n",
    "            net.eval()\n",
    "            #train_corrects, train_loss = evaluate_attacked_model(trainloader, \"clean_train\", vanila, limit=1000)\n",
    "            #test_corrects, test_loss = evaluate_attacked_model(testloader, \"clean_test\", vanila, limit=1000)\n",
    "            net.train()\n",
    "            #print(train_corrects, train_loss)\n",
    "            #print(test_corrects, test_loss)\n",
    "            net.eval()\n",
    "            #train_corrects, train_loss = evaluate_attacked_model(trainloader, \"pgd5_train\", pgd5, limit=200)\n",
    "            #test_corrects, test_loss = evaluate_attacked_model(testloader, \"pgd5_test\", pgd5, limit=200)\n",
    "            net.train()\n",
    "            #print(train_corrects, train_loss)\n",
    "            #print(test_corrects, test_loss)\n",
    "            fn = f\"models/{MODELTYPE}_lr{LR}_{epoch}epochs_{i}_batches.pth\"\n",
    "            torch.save(net.state_dict(), fn)\n",
    "            net.eval()\n",
    "            #train_corrects, train_loss = evaluate_attacked_model(testloader2, \"aa_test\", aa, limit=16)\n",
    "            net.train()\n",
    "            #print(test_corrects, test_loss)\n",
    "        if epoch == 3:\n",
    "            break # stop training here, the last \"epoch\" is for reporting\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        adv = random.randint(1, 1)\n",
    "        if adv == 1:\n",
    "            inputs = pgd5(inputs, labels)\n",
    "        outputs = net(inputs) # can we actually get rid of the clean samples completely?\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        #print(loss.item())\n",
    "        if i % 25 == 24:    # print every 125 mini-batches\n",
    "            print(f'[{epoch}, {i + 1:5d}] loss: {running_loss / 25}')\n",
    "            #print(f\"Adv loss: {adv_loss / adv_runs})\")\n",
    "            running_loss = 0.0\n",
    "            adv_loss, clean_loss, adv_runs = 0.0, 0.0, 0\n",
    "            #test_corrects, test_loss = evaluate_attacked_model(testloader, \"pgd10_test\", pgd10, limit=200, model=net)\n",
    "            with torch.no_grad():\n",
    "                counter = 0\n",
    "        if i % 625 == 624:\n",
    "            scheduler.step()\n",
    "# best clean / adv splits got with cosine (0.05 -> 0.005): 93.75% / 41.96%\n",
    "# try to mix and match it with SAM (sharpness aware minimization) (doubles the training time though for standard thing)\n",
    "# and also with target logit loss\n",
    "# if cosine layer wins the key might be less overfitting (it's harder to overfit on cosine similarity)\n",
    "# because the decision boundaries are more well-rounded?\n",
    "# quickly pull up some t-SNE (scikit-learn) plots of feature maps to look at the feature maps of the linear vs cosine layers\n",
    "# best clean / adv splits got with linear (0.02? -> 0.001): 91.01% / 28.57% (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8a88e66-01a1-4d62-bd2d-1d10c4e84d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"/workspace/robustbench/models/Peng2023Robust_extratrain_lr0.0001_0epochs_625_batches.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3975547c-c33d-43ca-bb5b-00d971c18ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"net_state_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c4bb4cb-0dde-4881-97ec-2c24ac58b3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pgd10_test accuracy: 75.94 (7594 / 10000) %\n"
     ]
    }
   ],
   "source": [
    "import torchattacks\n",
    "pgd10 = torchattacks.PGD(net)\n",
    "test_corrects, test_loss = evaluate_attacked_model(testloader, \"pgd10_test\", pgd10, limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8511e4b5-ed2e-4c92-a2b4-4c7f7e09e262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pgd10_test accuracy: 75.05 (7505 / 10000) %\n"
     ]
    }
   ],
   "source": [
    "import torchattacks\n",
    "pgd10 = torchattacks.PGD(model, steps=10)\n",
    "# 75.x% robustness\n",
    "test_corrects, test_loss = evaluate_attacked_model(testloader, \"pgd10_test\", pgd10, limit=10000, model=model)\n",
    "# baseline: PGD-10: 75.05%; PGD-20: 74.33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18c5fb8b-7380-4418-9895-5d3513c06ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pgd10_test accuracy: 75.35 (7535 / 10000) %\n"
     ]
    }
   ],
   "source": [
    "import torchattacks\n",
    "pgd10 = torchattacks.PGD(model, steps=10)\n",
    "# managed to capture it before gradient obfuscation... maybe is low learning rate the key?\n",
    "test_corrects, test_loss = evaluate_attacked_model(testloader, \"pgd10_test\", pgd10, limit=10000, model=net)\n",
    "# got 75.35% pgd10_test transfer accuracy on 625-step training!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "142c3564-2e8e-4a98-b0b8-47c102e56200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atk_test accuracy: 79.00390625 (809 / 1024) %\n"
     ]
    }
   ],
   "source": [
    "atk = torchattacks.PGD(net, steps=20)\n",
    "test_corrects, test_loss = evaluate_attacked_model(testloader, \"atk_test\", atk, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517c2c7-31eb-4fd6-9773-8c51251039fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
